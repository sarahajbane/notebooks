{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarahajbane/notebooks/blob/main/Pretrain_Torchgeo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SYR6xDVkUZY"
      },
      "outputs": [],
      "source": [
        "%pip install torchgeo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "k5YngX8N50CH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f461bc03-9eca-4c80-c0d2-2a55d2e029c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchgeo # Library from which we'll export the pretrained models\n",
        "import kagglehub\n",
        "import os\n",
        "import zipfile\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "8OkQjNK-k-it"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/My Drive'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWWBJD7clTnd",
        "outputId": "3b7fa929-f452-46a0-d7ce-eb3897c220be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.path.exists(os.path.join(path, \"MARIDA.zip\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUDz7a8Xn4oi",
        "outputId": "9f74aaea-9d8c-4d9a-92f9-72a5203cee43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the dataset as it's in a zip file (inspired from Jayash)\n",
        "if os.path.exists(\"/content/drive/My Drive/MARIDA.zip\"):\n",
        "    print(\"Extracting MARIDA dataset...\")\n",
        "    with zipfile.ZipFile(\"/content/drive/My Drive/MARIDA.zip\", 'r') as zip_ref:\n",
        "        zip_ref.extractall('./data')\n",
        "    print(\"Dataset extracted!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-JGOC4mnHhP",
        "outputId": "fef400ba-c08b-4665-a644-2775fa76e06d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MARIDA dataset...\n",
            "Dataset extracted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"./data/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUTY5Mmb151e",
        "outputId": "673da4b3-1d17-448c-c381-0a8688009164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MARIDA.zip']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(\"./data/MARIDA.zip\"):\n",
        "    print(\"Extracting MARIDA dataset...\")\n",
        "    with zipfile.ZipFile(\"./data/MARIDA.zip\", 'r') as zip_ref:\n",
        "        zip_ref.extractall('./data')\n",
        "    print(\"Dataset extracted!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLu_oKF6xJrs",
        "outputId": "fc19b1c0-3760-4de0-b03c-ae1d0aadb256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MARIDA dataset...\n",
            "Dataset extracted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from torchgeo.datamodules import EuroSAT100DataModule\n",
        "from torchgeo.models import ResNet18_Weights\n",
        "from torchgeo.trainers import SementicSegmentationTask\n",
        "\n",
        "task = ClassificationTask(\n",
        "    model='resnet18',\n",
        "    loss='ce',\n",
        "    weights=weights,\n",
        "    in_channels=13,\n",
        "    num_classes=10,\n",
        "    lr=0.001,\n",
        "    patience=5,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "zmrJuOrGGpLX",
        "outputId": "69cb2245-8b53-4771-f082-a87dc7d0bae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'ClassificationTask' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-16aa1fc83e5b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m task = ClassificationTask(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'resnet18'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ce'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ClassificationTask' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-lijP-kuGr1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class names from the MARIDA repo\n",
        "class_mapping = {\n",
        "    1: 'Marine Debris',\n",
        "    2: 'Dense Sargassum',\n",
        "    3: 'Sparse Sargassum',\n",
        "    4: 'Natural Organic Material',\n",
        "    5: 'Ship',\n",
        "    6: 'Clouds',\n",
        "    7: 'Marine Water',\n",
        "    8: 'Sediment-Laden Water',\n",
        "    9: 'Foam',\n",
        "    10: 'Turbid Water',\n",
        "    11: 'Shallow Water',\n",
        "    12: 'Waves',\n",
        "    13: 'Cloud Shadows',\n",
        "    14: 'Wakes',\n",
        "    15: 'Mixed Water'\n",
        "}\n",
        "\n",
        "\n",
        "# Define color mapping for visualization (used Deep seek for this)\n",
        "color_mapping = {\n",
        "    1: (255, 0, 0),      # Marine Debris - Red\n",
        "    2: (0, 128, 0),      # Dense Sargassum - Green\n",
        "    3: (144, 238, 144),  # Sparse Sargassum - Light Green\n",
        "    4: (139, 69, 19),    # Natural Organic Material - Brown\n",
        "    5: (128, 128, 128),  # Ship - Gray\n",
        "    6: (255, 255, 255),  # Clouds - White\n",
        "    7: (0, 0, 255),      # Marine Water - Blue\n",
        "    8: (210, 180, 140),  # Sediment-Laden Water - Tan\n",
        "    9: (255, 255, 224),  # Foam - Light Yellow\n",
        "    10: (64, 224, 208),  # Turbid Water - Turquoise\n",
        "    11: (176, 224, 230), # Shallow Water - Powder Blue\n",
        "    12: (0, 191, 255),   # Waves - Deep Sky Blue\n",
        "    13: (105, 105, 105), # Cloud Shadows - Dim Gray\n",
        "    14: (220, 220, 220), # Wakes - Gainsboro\n",
        "    15: (70, 130, 180)   # Mixed Water - Steel Blue\n",
        "}\n"
      ],
      "metadata": {
        "id": "3r6DAM6Q0oaR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}